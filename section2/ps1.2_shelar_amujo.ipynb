{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'classify_test_instance' from 'utils.decision_list' (/Users/onkars/Documents/PSYC681/Problem Set/nlp1_rit_course/section2/utils/decision_list.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlog_likelihood\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     count_feature_frequencies,\n\u001b[1;32m      5\u001b[0m     calculate_probabilities,\n\u001b[1;32m      6\u001b[0m     calculate_log_likelihood,\n\u001b[1;32m      7\u001b[0m     rank_features_by_log_likelihood\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecision_list\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_decision_list, classify_test_data, get_default_sense\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate_classifier_with_metrics\n",
      "File \u001b[0;32m~/Documents/PSYC681/Problem Set/nlp1_rit_course/section2/utils/evaluation.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, confusion_matrix, precision_recall_fscore_support\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecision_list\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classify_test_instance\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_classifier_with_metrics\u001b[39m(predictions, true_labels):\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    Evaluate the classifier by computing accuracy, confusion matrix, precision, recall, and F1-score.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    :return: Accuracy, confusion matrix, precision, recall, F1-score.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'classify_test_instance' from 'utils.decision_list' (/Users/onkars/Documents/PSYC681/Problem Set/nlp1_rit_course/section2/utils/decision_list.py)"
     ]
    }
   ],
   "source": [
    "from utils.preprocessing import load_data, clean_text\n",
    "from utils.feature_extraction import extract_all_features\n",
    "from utils.log_likelihood import (\n",
    "    count_feature_frequencies,\n",
    "    calculate_probabilities,\n",
    "    calculate_log_likelihood,\n",
    "    rank_features_by_log_likelihood\n",
    ")\n",
    "from utils.decision_list import build_decision_list, classify_test_data, get_default_sense\n",
    "from utils.evaluation import evaluate_classifier_with_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_bass = '/Users/onkars/Documents/PSYC681/Problem Set/nlp1_rit_course/section2/datasets/bass_trn.txt'\n",
    "train_file_sake = '/Users/onkars/Documents/PSYC681/Problem Set/nlp1_rit_course/section2/datasets/sake_trn.txt'\n",
    "test_file_bass = '/Users/onkars/Documents/PSYC681/Problem Set/nlp1_rit_course/section2/datasets/bass_tst.txt'\n",
    "test_file_sake = '/Users/onkars/Documents/PSYC681/Problem Set/nlp1_rit_course/section2/datasets/sake_tst.txt'\n",
    "\n",
    "train_data_bass = load_data(train_file_bass)\n",
    "train_data_sake = load_data(train_file_sake)\n",
    "\n",
    "test_data_bass = load_data(test_file_bass)\n",
    "test_data_sake = load_data(test_file_sake)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_bass[:3])  \n",
    "print(train_data_sake[:3])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_extraction(data):\n",
    "    \"\"\"\n",
    "    Applies feature extraction to each instance in the dataset.\n",
    "    :param data: List of dictionaries containing context, target word, and sense.\n",
    "    :return: List of dictionaries, each containing the extracted features and the sense label.\n",
    "    \"\"\"\n",
    "    feature_data = []\n",
    "    for instance in data:\n",
    "        features = extract_all_features(instance)\n",
    "        features['sense'] = instance['sense']  # Keep the sense label for classification later\n",
    "        feature_data.append(features)\n",
    "    \n",
    "    return feature_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_bass = apply_feature_extraction(train_data_bass)\n",
    "test_features_bass = apply_feature_extraction(train_data_bass)\n",
    "\n",
    "train_features_sake = apply_feature_extraction(train_data_sake)\n",
    "test_features_sake = apply_feature_extraction(train_data_sake)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the first feature set to inspect\n",
    "display(train_features_bass[0])  \n",
    "display(train_features_sake[0])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Likelihood Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count feature frequencies for both senses (bass = fish/music, sake = beer/cause)\n",
    "freq_bass_fish, freq_bass_music, total_bass_fish, total_bass_music = count_feature_frequencies(\n",
    "    train_features_bass, sense_label1=\"*bass\", sense_label2=\"bass\"\n",
    ")\n",
    "\n",
    "freq_sake_beer, freq_sake_cause, total_sake_beer, total_sake_cause = count_feature_frequencies(\n",
    "    train_features_sake, sense_label1=\"*sake\", sense_label2=\"sake\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probabilities (apply Laplace smoothing)\n",
    "num_unique_features = len(set([f for data in train_features_bass for f in data if f != 'sense']))  # Unique features\n",
    "\n",
    "prob_bass_fish = calculate_probabilities(freq_bass_fish, total_bass_fish, num_unique_features=num_unique_features)\n",
    "prob_bass_music = calculate_probabilities(freq_bass_music, total_bass_music, num_unique_features=num_unique_features)\n",
    "\n",
    "prob_sake_beer = calculate_probabilities(freq_sake_beer, total_sake_beer, num_unique_features=num_unique_features)\n",
    "prob_sake_cause = calculate_probabilities(freq_sake_cause, total_sake_cause, num_unique_features=num_unique_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate log-likelihood ratios\n",
    "log_likelihood_bass = calculate_log_likelihood(prob_bass_fish, prob_bass_music)\n",
    "log_likelihood_sake = calculate_log_likelihood(prob_sake_beer, prob_sake_cause)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank features by log-likelihood (top features are most predictive)\n",
    "ranked_bass_features = rank_features_by_log_likelihood(log_likelihood_bass)\n",
    "ranked_sake_features = rank_features_by_log_likelihood(log_likelihood_sake)\n",
    "\n",
    "# Output the top 10 features\n",
    "print(\"Top 10 features for 'bass':\")\n",
    "for feature, score in ranked_bass_features[:10]:\n",
    "    print(f\"{feature}: {score}\")\n",
    "    \n",
    "print(\"\\nTop 10 features for 'sake':\")\n",
    "for feature, score in ranked_sake_features[:10]:\n",
    "    print(f\"{feature}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision List Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Build decision lists for 'bass' and 'sake'\n",
    "decision_list_bass = build_decision_list(ranked_bass_features, sense_label1=\"*bass\", sense_label2=\"bass\")\n",
    "decision_list_sake = build_decision_list(ranked_sake_features, sense_label1=\"*sake\", sense_label2=\"sake\")\n",
    "\n",
    "# Step 2: Get default senses from training data\n",
    "default_sense_bass = get_default_sense(train_data_bass, sense_label1=\"*bass\", sense_label2=\"bass\")\n",
    "default_sense_sake = get_default_sense(train_data_sake, sense_label1=\"*sake\", sense_label2=\"sake\")\n",
    "\n",
    "# Step 3: Classify the test data\n",
    "predictions_bass = classify_test_data(test_data_bass, decision_list_bass, default_sense_bass)\n",
    "predictions_sake = classify_test_data(test_data_sake, decision_list_sake, default_sense_sake)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_bass, conf_matrix_bass, precision_bass, recall_bass, f1_bass = evaluate_classifier_with_metrics(\n",
    "    predictions_bass, [instance['sense'] for instance in test_data_bass]\n",
    ")\n",
    "accuracy_sake, conf_matrix_sake, precision_sake, recall_sake, f1_sake = evaluate_classifier_with_metrics(\n",
    "    predictions_sake, [instance['sense'] for instance in test_data_sake]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output additional metrics for \"bass\" and \"sake\"\n",
    "print(f\"Bass Classifier - Accuracy: {accuracy_bass * 100:.2f}%, Precision: {precision_bass:.2f}, Recall: {recall_bass:.2f}, F1-Score: {f1_bass:.2f}\")\n",
    "print(\"Bass Confusion Matrix:\")\n",
    "print(conf_matrix_bass)\n",
    "\n",
    "print(f\"Sake Classifier - Accuracy: {accuracy_sake * 100:.2f}%, Precision: {precision_sake:.2f}, Recall: {recall_sake:.2f}, F1-Score: {f1_sake:.2f}\")\n",
    "print(\"Sake Confusion Matrix:\")\n",
    "print(conf_matrix_sake)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
